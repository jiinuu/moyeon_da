"""
íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
ì „ì²´ ETL íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë° ê´€ë¦¬

ì‹¤í–‰ ìˆœì„œ:
1. ë°ì´í„° ë ˆì´í¬ ì´ˆê¸°í™”
2. ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ ì´ˆê¸°í™”
3. Bronze: ë°ì´í„° ìˆ˜ì§‘ (Ingestion)
4. Silver: ë°ì´í„° ì •ì œ (Transformation)
5. Gold: ë°ì´í„° ì§‘ê³„ (Aggregation)
6. Serving: Dashboard ë°ì´í„° ìƒì„±
"""

import sys
from pathlib import Path
from datetime import datetime
import argparse

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
PIPELINE_DIR = Path(__file__).parent
sys.path.insert(0, str(PIPELINE_DIR))

from config import init_data_lake, get_config
from warehouse import DataWarehouse, init_warehouse
from ingestion import run_full_ingestion
from transformation import run_full_transformation


def run_pipeline(stages: list = None, verbose: bool = True):
    """
    ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    
    Args:
        stages: ì‹¤í–‰í•  ë‹¨ê³„ ëª©ë¡ (Noneì´ë©´ ì „ì²´ ì‹¤í–‰)
                ê°€ëŠ¥í•œ ê°’: ['init', 'ingest', 'transform', 'serve']
        verbose: ìƒì„¸ ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€
    """
    
    all_stages = ['init', 'ingest', 'transform', 'serve']
    stages = stages or all_stages
    
    start_time = datetime.now()
    
    print("=" * 70)
    print("ğŸš€ ì•ˆì‚°ì‹œ ì™¸êµ­ì¸ ë³´ìœ¡ë£Œ ì •ì±… ê°ì‚¬ - ë°ì´í„° íŒŒì´í”„ë¼ì¸")
    print("=" * 70)
    print(f"ğŸ“… ì‹¤í–‰ ì‹œì‘: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“‹ ì‹¤í–‰ ë‹¨ê³„: {stages}")
    print("=" * 70)
    
    results = {}
    
    try:
        # 1. ì´ˆê¸°í™” ë‹¨ê³„
        if 'init' in stages:
            print("\n" + "â”€" * 50)
            print("ğŸ“ [1/4] ë°ì´í„° ë ˆì´í¬ ë° ì›¨ì–´í•˜ìš°ìŠ¤ ì´ˆê¸°í™”")
            print("â”€" * 50)
            
            init_data_lake()
            init_warehouse()
            
            results['init'] = {'status': 'success'}
            print("âœ… ì´ˆê¸°í™” ì™„ë£Œ")
        
        # 2. ìˆ˜ì§‘ ë‹¨ê³„ (Bronze)
        if 'ingest' in stages:
            print("\n" + "â”€" * 50)
            print("ğŸ“¥ [2/4] Bronze Layer - ë°ì´í„° ìˆ˜ì§‘")
            print("â”€" * 50)
            
            run_full_ingestion()
            
            results['ingest'] = {'status': 'success'}
            print("âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        
        # 3. ë³€í™˜ ë‹¨ê³„ (Silver + Gold)
        if 'transform' in stages:
            print("\n" + "â”€" * 50)
            print("ğŸ”„ [3/4] Silver/Gold Layer - ë°ì´í„° ë³€í™˜")
            print("â”€" * 50)
            
            run_full_transformation()
            
            results['transform'] = {'status': 'success'}
            print("âœ… ë°ì´í„° ë³€í™˜ ì™„ë£Œ")
        
        # 4. ì„œë¹™ ë‹¨ê³„
        if 'serve' in stages:
            print("\n" + "â”€" * 50)
            print("ğŸ“Š [4/4] Serving Layer - Dashboard ë°ì´í„° ìƒì„±")
            print("â”€" * 50)
            
            # transformation.pyì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë¨
            from transformation import ServingLayer
            serving = ServingLayer()
            serving.run()
            
            results['serve'] = {'status': 'success'}
            print("âœ… Dashboard ë°ì´í„° ìƒì„± ì™„ë£Œ")
        
    except Exception as e:
        print(f"\nâŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        results['error'] = str(e)
        
        # ì˜¤ë¥˜ ë¡œê¹…
        try:
            with DataWarehouse() as dw:
                dw.log_pipeline_run(
                    pipeline_name="full_pipeline",
                    layer="error",
                    status="failed",
                    error_message=str(e)
                )
        except:
            pass
    
    # ì‹¤í–‰ ì™„ë£Œ ìš”ì•½
    end_time = datetime.now()
    duration = end_time - start_time
    
    print("\n" + "=" * 70)
    print("ğŸ“‹ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ ìš”ì•½")
    print("=" * 70)
    print(f"â±ï¸  ì†Œìš” ì‹œê°„: {duration}")
    print(f"ğŸ“Š ì‹¤í–‰ ê²°ê³¼:")
    
    for stage, result in results.items():
        status = result.get('status', 'unknown')
        status_icon = "âœ…" if status == 'success' else "âŒ"
        print(f"    {status_icon} {stage}: {status}")
    
    # ë°ì´í„° ë ˆì´í¬ í˜„í™© ì¶œë ¥
    config = get_config()
    print(f"\nğŸ“ ë°ì´í„° ë ˆì´í¬ ìœ„ì¹˜: {config['data_lake_root']}")
    print(f"ğŸ—„ï¸  ì›¨ì–´í•˜ìš°ìŠ¤ DB: {config['warehouse_db']}")
    
    print("=" * 70)
    
    return results


def show_status():
    """íŒŒì´í”„ë¼ì¸ ìƒíƒœ í™•ì¸"""
    
    print("=" * 60)
    print("ğŸ“Š ë°ì´í„° íŒŒì´í”„ë¼ì¸ ìƒíƒœ")
    print("=" * 60)
    
    config = get_config()
    
    # ë°ì´í„° ë ˆì´í¬ ìƒíƒœ
    print("\nğŸ“ ë°ì´í„° ë ˆì´í¬:")
    for layer, path in config["layers"].items():
        layer_path = Path(path)
        if layer_path.exists():
            files = list(layer_path.rglob("*"))
            file_count = len([f for f in files if f.is_file()])
            print(f"  âœ… {layer.upper()}: {file_count} files")
        else:
            print(f"  âš ï¸ {layer.upper()}: Not initialized")
    
    # ì›¨ì–´í•˜ìš°ìŠ¤ ìƒíƒœ
    print("\nğŸ—„ï¸  ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤:")
    db_path = Path(config["warehouse_db"])
    if db_path.exists():
        print(f"  âœ… DB exists: {db_path}")
        
        try:
            with DataWarehouse() as dw:
                tables = dw.list_tables()
                for schema, table_list in tables.items():
                    if table_list:
                        print(f"  ğŸ“‹ {schema}: {len(table_list)} tables")
        except Exception as e:
            print(f"  âš ï¸ Cannot read DB: {e}")
    else:
        print(f"  âš ï¸ DB not found")
    
    # ìµœê·¼ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë¡œê·¸
    print("\nğŸ“œ ìµœê·¼ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰:")
    try:
        with DataWarehouse() as dw:
            runs = dw.query("""
                SELECT pipeline_name, layer, status, completed_at, rows_processed
                FROM metadata.pipeline_runs
                ORDER BY completed_at DESC
                LIMIT 5
            """)
            if not runs.empty:
                for _, row in runs.iterrows():
                    status_icon = "âœ…" if row['status'] == 'success' else "âŒ"
                    print(f"  {status_icon} {row['pipeline_name']} ({row['layer']}): "
                          f"{row['rows_processed']} rows")
            else:
                print("  â„¹ï¸ No pipeline runs recorded")
    except Exception as e:
        print(f"  âš ï¸ Cannot read logs: {e}")
    
    print("=" * 60)


def main():
    """ë©”ì¸ CLI ì—”íŠ¸ë¦¬í¬ì¸íŠ¸"""
    
    parser = argparse.ArgumentParser(
        description="ì•ˆì‚°ì‹œ ì™¸êµ­ì¸ ë³´ìœ¡ë£Œ ì •ì±… ê°ì‚¬ - ë°ì´í„° íŒŒì´í”„ë¼ì¸"
    )
    
    parser.add_argument(
        "command",
        choices=["run", "status", "init", "ingest", "transform", "serve"],
        help="ì‹¤í–‰í•  ëª…ë ¹"
    )
    
    parser.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥"
    )
    
    args = parser.parse_args()
    
    if args.command == "run":
        run_pipeline(verbose=args.verbose)
    
    elif args.command == "status":
        show_status()
    
    elif args.command == "init":
        run_pipeline(stages=['init'], verbose=args.verbose)
    
    elif args.command == "ingest":
        run_pipeline(stages=['init', 'ingest'], verbose=args.verbose)
    
    elif args.command == "transform":
        run_pipeline(stages=['transform'], verbose=args.verbose)
    
    elif args.command == "serve":
        run_pipeline(stages=['serve'], verbose=args.verbose)


if __name__ == "__main__":
    # ì¸ì ì—†ì´ ì‹¤í–‰í•˜ë©´ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    if len(sys.argv) == 1:
        run_pipeline()
    else:
        main()
