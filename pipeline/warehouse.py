"""
ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ ê´€ë¦¬ ëª¨ë“ˆ
DuckDB ê¸°ë°˜ OLAP ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤

ê¸°ëŠ¥:
- í…Œì´ë¸” ìƒì„±/ê´€ë¦¬
- ë°ì´í„° ì ì¬
- ì¿¼ë¦¬ ì‹¤í–‰
- ë©”íƒ€ë°ì´í„° ê´€ë¦¬
"""

import duckdb
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict, List, Any
import json

from config import (
    WAREHOUSE_DB_PATH,
    SCHEMAS,
    BRONZE_LAYER,
    SILVER_LAYER,
    GOLD_LAYER
)


class DataWarehouse:
    """DuckDB ê¸°ë°˜ ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, db_path: Optional[Path] = None):
        self.db_path = db_path or WAREHOUSE_DB_PATH
        self.conn = None
    
    def connect(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
        self.conn = duckdb.connect(str(self.db_path))
        print(f"âœ… Connected to: {self.db_path}")
        return self
    
    def disconnect(self):
        """ì—°ê²° ì¢…ë£Œ"""
        if self.conn:
            self.conn.close()
            self.conn = None
            print("ğŸ”Œ Disconnected from database")
    
    def __enter__(self):
        return self.connect()
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.disconnect()
    
    # =============================================
    # ìŠ¤í‚¤ë§ˆ ë° í…Œì´ë¸” ê´€ë¦¬
    # =============================================
    
    def init_schemas(self):
        """ëª¨ë“  ìŠ¤í‚¤ë§ˆ(ë ˆì´ì–´) ì´ˆê¸°í™”"""
        layers = ['bronze', 'silver', 'gold']
        
        for layer in layers:
            self.conn.execute(f"CREATE SCHEMA IF NOT EXISTS {layer}")
            print(f"âœ… Schema created: {layer}")
        
        # ë©”íƒ€ë°ì´í„° ìŠ¤í‚¤ë§ˆ
        self.conn.execute("CREATE SCHEMA IF NOT EXISTS metadata")
        
        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë¡œê·¸ í…Œì´ë¸”
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS metadata.pipeline_runs (
                run_id VARCHAR PRIMARY KEY,
                pipeline_name VARCHAR,
                layer VARCHAR,
                started_at TIMESTAMP,
                completed_at TIMESTAMP,
                status VARCHAR,
                rows_processed INTEGER,
                error_message TEXT
            )
        """)
        
        # ë°ì´í„° í’ˆì§ˆ ë¡œê·¸ í…Œì´ë¸”
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS metadata.quality_checks (
                check_id VARCHAR PRIMARY KEY,
                table_name VARCHAR,
                check_type VARCHAR,
                check_result VARCHAR,
                details JSON,
                checked_at TIMESTAMP
            )
        """)
        
        print("âœ… Metadata tables created")
        return self
    
    def create_table(self, layer: str, table_name: str, schema: str):
        """í…Œì´ë¸” ìƒì„±"""
        full_table_name = f"{layer}.{table_name}"
        
        self.conn.execute(f"""
            CREATE TABLE IF NOT EXISTS {full_table_name} (
                {schema}
            )
        """)
        print(f"âœ… Table created: {full_table_name}")
        return self
    
    def init_all_tables(self):
        """ëª¨ë“  í…Œì´ë¸” ì´ˆê¸°í™”"""
        for layer, tables in SCHEMAS.items():
            for table_name, schema in tables.items():
                self.create_table(layer, table_name, schema)
        
        return self
    
    # =============================================
    # ë°ì´í„° ì ì¬ (Loading)
    # =============================================
    
    def insert_bronze_data(self, table_name: str, data: Dict[str, Any]):
        """Bronze ë ˆì´ì–´ì— ì›ë³¸ ë°ì´í„° ì ì¬"""
        import uuid
        
        if table_name == "raw_kosis_data":
            self.conn.execute("""
                INSERT INTO bronze.raw_kosis_data 
                (source_id, table_id, raw_data, ingested_at, source_url)
                VALUES (?, ?, ?, ?, ?)
            """, [
                data.get("source_id", str(uuid.uuid4())),
                data.get("table_id"),
                json.dumps(data.get("raw_data", {})),
                datetime.now(),
                data.get("source_url", "")
            ])
        
        elif table_name == "raw_policy_data":
            self.conn.execute("""
                INSERT INTO bronze.raw_policy_data
                (document_id, document_name, raw_content, extracted_at, source_path)
                VALUES (?, ?, ?, ?, ?)
            """, [
                data.get("document_id", str(uuid.uuid4())),
                data.get("document_name"),
                data.get("raw_content", ""),
                datetime.now(),
                data.get("source_path", "")
            ])
        
        return self
    
    def insert_silver_data(self, table_name: str, records: List[Dict]):
        """Silver ë ˆì´ì–´ì— ì •ì œëœ ë°ì´í„° ì ì¬"""
        import pandas as pd
        
        df = pd.DataFrame(records)
        
        # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ì ì¬ (UPSERT)
        self.conn.execute(f"DELETE FROM silver.{table_name}")
        self.conn.execute(f"INSERT INTO silver.{table_name} SELECT * FROM df")
        
        print(f"âœ… Inserted {len(records)} rows into silver.{table_name}")
        return self
    
    def insert_gold_data(self, table_name: str, records: List[Dict]):
        """Gold ë ˆì´ì–´ì— ì§‘ê³„ ë°ì´í„° ì ì¬"""
        import pandas as pd
        
        df = pd.DataFrame(records)
        
        # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ì ì¬
        self.conn.execute(f"DELETE FROM gold.{table_name}")
        self.conn.execute(f"INSERT INTO gold.{table_name} SELECT * FROM df")
        
        print(f"âœ… Inserted {len(records)} rows into gold.{table_name}")
        return self
    
    # =============================================
    # ì¿¼ë¦¬ ì‹¤í–‰
    # =============================================
    
    def query(self, sql: str):
        """SQL ì¿¼ë¦¬ ì‹¤í–‰ ë° DataFrame ë°˜í™˜"""
        return self.conn.execute(sql).df()
    
    def execute(self, sql: str):
        """SQL ì‹¤í–‰ (ë°˜í™˜ê°’ ì—†ìŒ)"""
        self.conn.execute(sql)
        return self
    
    # =============================================
    # ë©”íƒ€ë°ì´í„° ê´€ë¦¬
    # =============================================
    
    def log_pipeline_run(self, pipeline_name: str, layer: str, 
                         status: str, rows_processed: int = 0, 
                         error_message: str = None):
        """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë¡œê·¸ ê¸°ë¡"""
        import uuid
        
        self.conn.execute("""
            INSERT INTO metadata.pipeline_runs
            (run_id, pipeline_name, layer, started_at, completed_at, 
             status, rows_processed, error_message)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """, [
            str(uuid.uuid4()),
            pipeline_name,
            layer,
            datetime.now(),
            datetime.now(),
            status,
            rows_processed,
            error_message
        ])
        return self
    
    def log_quality_check(self, table_name: str, check_type: str,
                          check_result: str, details: Dict = None):
        """ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬ ë¡œê·¸ ê¸°ë¡"""
        import uuid
        
        self.conn.execute("""
            INSERT INTO metadata.quality_checks
            (check_id, table_name, check_type, check_result, details, checked_at)
            VALUES (?, ?, ?, ?, ?, ?)
        """, [
            str(uuid.uuid4()),
            table_name,
            check_type,
            check_result,
            json.dumps(details or {}),
            datetime.now()
        ])
        return self
    
    # =============================================
    # ìœ í‹¸ë¦¬í‹°
    # =============================================
    
    def get_table_stats(self, full_table_name: str) -> Dict:
        """í…Œì´ë¸” í†µê³„ ì¡°íšŒ"""
        try:
            count = self.conn.execute(
                f"SELECT COUNT(*) FROM {full_table_name}"
            ).fetchone()[0]
            
            return {
                "table": full_table_name,
                "row_count": count
            }
        except Exception as e:
            return {"table": full_table_name, "error": str(e)}
    
    def export_to_parquet(self, table_name: str, output_path: Path):
        """í…Œì´ë¸”ì„ Parquet íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        self.conn.execute(f"""
            COPY {table_name} TO '{output_path}' (FORMAT PARQUET)
        """)
        print(f"âœ… Exported {table_name} to {output_path}")
        return self
    
    def export_to_json(self, table_name: str, output_path: Path):
        """í…Œì´ë¸”ì„ JSON íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        df = self.query(f"SELECT * FROM {table_name}")
        df.to_json(output_path, orient="records", force_ascii=False, indent=2)
        print(f"âœ… Exported {table_name} to {output_path}")
        return self
    
    def list_tables(self) -> Dict[str, List[str]]:
        """ëª¨ë“  ìŠ¤í‚¤ë§ˆì˜ í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ"""
        result = {}
        
        for schema in ['bronze', 'silver', 'gold', 'metadata']:
            try:
                tables = self.conn.execute(f"""
                    SELECT table_name 
                    FROM information_schema.tables 
                    WHERE table_schema = '{schema}'
                """).fetchall()
                result[schema] = [t[0] for t in tables]
            except:
                result[schema] = []
        
        return result


def init_warehouse():
    """ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ ì´ˆê¸°í™”"""
    with DataWarehouse() as dw:
        dw.init_schemas()
        dw.init_all_tables()
        
        print("\nğŸ“Š í…Œì´ë¸” ëª©ë¡:")
        tables = dw.list_tables()
        for schema, table_list in tables.items():
            print(f"  {schema}: {table_list}")
    
    return True


if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ—„ï¸ ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ ì´ˆê¸°í™”")
    print("=" * 60)
    
    init_warehouse()
    
    print("\nâœ… ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
